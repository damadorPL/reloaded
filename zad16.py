#!/usr/bin/env python3
"""
S04E02 - Wykrywanie sfaÅ‚szowanych wynikÃ³w badaÅ„ przy uÅ¼yciu fine-tuningu
Multi-engine: openai, lmstudio, anything, gemini, claude
Wykorzystuje fine-tuning modelu do klasyfikacji danych z czujnikÃ³w robotÃ³w
"""
import argparse
import os
import sys
import json
import requests
import zipfile
import time
import logging
from pathlib import Path
from dotenv import load_dotenv
from typing import TypedDict, Optional, List, Dict, Any, Tuple
from langgraph.graph import StateGraph, START, END

# Konfiguracja loggera
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# 1. Konfiguracja i wykrywanie silnika
load_dotenv(override=True)

parser = argparse.ArgumentParser(description="Wykrywanie sfaÅ‚szowanych danych (multi-engine)")
parser.add_argument("--engine", choices=["openai", "lmstudio", "anything", "gemini", "claude"],
                    help="LLM backend to use")
parser.add_argument("--skip-training", action="store_true", 
                    help="PomiÅ„ trening i uÅ¼yj istniejÄ…cego modelu")
parser.add_argument("--model-id", type=str, 
                    help="ID wytrenowanego modelu do uÅ¼ycia")
args = parser.parse_args()

ENGINE: Optional[str] = None
if args.engine:
    ENGINE = args.engine.lower()
elif os.getenv("LLM_ENGINE"):
    ENGINE = os.getenv("LLM_ENGINE").lower()
else:
    # Dla fine-tuningu najlepiej uÅ¼ywaÄ‡ OpenAI
    ENGINE = "openai"

if ENGINE not in {"openai", "lmstudio", "anything", "gemini", "claude"}:
    print(f"âŒ NieobsÅ‚ugiwany silnik: {ENGINE}", file=sys.stderr)
    sys.exit(1)

# Dla fine-tuningu wymagany jest OpenAI
if not args.skip_training and ENGINE != "openai":
    print("âš ï¸  Fine-tuning jest dostÄ™pny tylko dla OpenAI. PrzeÅ‚Ä…czam na OpenAI.")
    ENGINE = "openai"

print(f"ğŸ”„ ENGINE wykryty: {ENGINE}")

# Sprawdzenie zmiennych Å›rodowiskowych
LAB_DATA_URL: str = os.getenv("LAB_DATA_URL")
REPORT_URL: str = os.getenv("REPORT_URL")
CENTRALA_API_KEY: str = os.getenv("CENTRALA_API_KEY")

if not all([LAB_DATA_URL, REPORT_URL, CENTRALA_API_KEY]):
    print("âŒ Brak wymaganych zmiennych: LAB_DATA_URL, REPORT_URL, CENTRALA_API_KEY", file=sys.stderr)
    sys.exit(1)

# Konfiguracja modelu
if ENGINE == "openai":
    MODEL_NAME: str = os.getenv("MODEL_NAME") or os.getenv("MODEL_NAME_OPENAI", "gpt-4o-mini")
    BASE_MODEL_FOR_FINETUNING: str = "gpt-4o-mini-2024-07-18"  # Model bazowy do fine-tuningu
elif ENGINE == "claude":
    MODEL_NAME = os.getenv("MODEL_NAME") or os.getenv("MODEL_NAME_CLAUDE", "claude-sonnet-4-20250514")
elif ENGINE == "gemini":
    MODEL_NAME = os.getenv("MODEL_NAME") or os.getenv("MODEL_NAME_GEMINI", "gemini-2.5-pro-latest")
elif ENGINE == "lmstudio":
    MODEL_NAME = os.getenv("MODEL_NAME") or os.getenv("MODEL_NAME_LM", "llama-3.3-70b-instruct")
elif ENGINE == "anything":
    MODEL_NAME = os.getenv("MODEL_NAME") or os.getenv("MODEL_NAME_ANY", "llama-3.3-70b-instruct")

print(f"âœ… Model: {MODEL_NAME}")

# Sprawdzenie API keys
if ENGINE == "openai" and not os.getenv("OPENAI_API_KEY"):
    print("âŒ Brak OPENAI_API_KEY", file=sys.stderr)
    sys.exit(1)

# 2. Typowanie stanu pipeline
class PipelineState(TypedDict, total=False):
    lab_data_dir: Path
    training_file_path: Path
    training_file_id: Optional[str]
    fine_tune_job_id: Optional[str]
    fine_tuned_model_id: Optional[str]
    verification_results: List[Tuple[str, bool]]  # (id, is_correct)
    correct_ids: List[str]
    result: Optional[str]

# 3. Funkcje pomocnicze
def download_and_extract_data(dest_dir: Path) -> None:
    """Pobiera i rozpakowuje dane laboratoryjne"""
    # SprawdÅº czy pliki juÅ¼ istniejÄ… (z dokumentÃ³w)
    expected_files = ["correct.txt", "incorrect.txt", "verify.txt"]
    root_files_exist = all((Path(f).exists() for f in expected_files))
    
    if root_files_exist:
        logger.info("ğŸ“‚ Znaleziono pliki lokalne w katalogu gÅ‚Ã³wnym, kopiujÄ™...")
        dest_dir.mkdir(parents=True, exist_ok=True)
        for filename in expected_files:
            src = Path(filename)
            dst = dest_dir / filename
            if src.exists():
                dst.write_text(src.read_text(encoding="utf-8"), encoding="utf-8")
                logger.info(f"   âœ… Skopiowano {filename}")
        return
    
    # JeÅ›li nie ma lokalnych plikÃ³w, pobierz z URL
    dest_dir.mkdir(parents=True, exist_ok=True)
    zip_path = dest_dir / "lab_data.zip"
    
    logger.info(f"ğŸ“¥ Pobieranie danych z {LAB_DATA_URL}...")
    
    try:
        response = requests.get(LAB_DATA_URL, stream=True)
        response.raise_for_status()
        
        with open(zip_path, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        
        logger.info("ğŸ“¦ Rozpakowywanie archiwum...")
        with zipfile.ZipFile(zip_path, "r") as zf:
            # SprawdÅº zawartoÅ›Ä‡ archiwum
            file_list = zf.namelist()
            logger.info(f"   Pliki w archiwum: {file_list}")
            
            # Rozpakuj wszystko
            zf.extractall(dest_dir)
        
        # SprawdÅº czy pliki sÄ… w podkatalogu i przenieÅ› je do gÅ‚Ã³wnego katalogu
        for subdir in dest_dir.iterdir():
            if subdir.is_dir():
                for file in subdir.iterdir():
                    if file.name in expected_files:
                        target = dest_dir / file.name
                        file.rename(target)
                        logger.info(f"   âœ… Przeniesiono {file.name} z {subdir.name}")
        
        # UsuÅ„ archiwum
        zip_path.unlink()
        
        # Po rozpakowaniu, jeÅ›li brakuje incorrect.txt, a jest incorect.txt, kopiuj/pliku
        incorrect_path = dest_dir / "incorrect.txt"
        incorect_path = dest_dir / "incorect.txt"
        if not incorrect_path.exists() and incorect_path.exists():
            incorect_path.rename(incorrect_path)
            logger.info("   âœ… Skorygowano nazwÄ™ pliku: incorect.txt -> incorrect.txt")

        # SprawdÅº czy wszystkie pliki sÄ… obecne
        for filename in expected_files:
            if not (dest_dir / filename).exists():
                logger.error(f"âŒ Brak pliku: {filename}")
                raise FileNotFoundError(f"Nie znaleziono pliku {filename} po rozpakowaniu")
        
        logger.info("âœ… Dane rozpakowane pomyÅ›lnie")
        
    except Exception as e:
        logger.error(f"âŒ BÅ‚Ä…d podczas pobierania/rozpakowywania: {e}")
        raise

def prepare_training_data(data_dir: Path, output_file: Path) -> int:
    """Przygotowuje dane treningowe w formacie JSONL"""
    logger.info("ğŸ“ Przygotowywanie danych treningowych...")
    
    entries = []
    
    # Wczytaj dane poprawne
    correct_file = data_dir / "correct.txt"
    with open(correct_file, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line:
                entries.append({
                    "messages": [
                        {"role": "system", "content": "validate data"},
                        {"role": "user", "content": line},
                        {"role": "assistant", "content": "1"}
                    ]
                })
    
    logger.info(f"âœ… ZaÅ‚adowano {len(entries)} poprawnych prÃ³bek")
    
    # Wczytaj dane niepoprawne - sprawdÅº rÃ³Å¼ne warianty nazwy
    incorrect_count = 0
    incorrect_variants = ["incorrect.txt", "incorect.txt"]  # Z bÅ‚Ä™dem w nazwie
    incorrect_file = None
    
    for variant in incorrect_variants:
        test_file = data_dir / variant
        if test_file.exists():
            incorrect_file = test_file
            logger.info(f"   Znaleziono plik z nieprawidÅ‚owymi danymi: {variant}")
            break
    
    if not incorrect_file:
        logger.error("âŒ Nie znaleziono pliku z nieprawidÅ‚owymi danymi (incorrect.txt lub incorect.txt)")
        return 0
    
    with open(incorrect_file, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line:
                entries.append({
                    "messages": [
                        {"role": "system", "content": "validate data"},
                        {"role": "user", "content": line},
                        {"role": "assistant", "content": "0"}
                    ]
                })
                incorrect_count += 1
    
    logger.info(f"âœ… ZaÅ‚adowano {incorrect_count} niepoprawnych prÃ³bek")
    
    # Zapisz do pliku JSONL
    output_file.parent.mkdir(parents=True, exist_ok=True)
    with open(output_file, "w", encoding="utf-8") as f:
        for entry in entries:
            f.write(json.dumps(entry) + "\n")
    
    logger.info(f"ğŸ’¾ Zapisano {len(entries)} prÃ³bek do {output_file}")
    return len(entries)

def upload_training_file(file_path: Path) -> Optional[str]:
    """Uploaduje plik treningowy do OpenAI"""
    from openai import OpenAI
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    logger.info("ğŸ“¤ WysyÅ‚anie pliku treningowego do OpenAI...")
    
    try:
        with open(file_path, "rb") as f:
            response = client.files.create(
                file=f,
                purpose="fine-tune"
            )
        
        file_id = response.id
        logger.info(f"âœ… Plik wysÅ‚any pomyÅ›lnie. ID: {file_id}")
        return file_id
        
    except Exception as e:
        logger.error(f"âŒ BÅ‚Ä…d podczas wysyÅ‚ania pliku: {e}")
        return None

def start_fine_tuning(training_file_id: str) -> Optional[str]:
    """Rozpoczyna proces fine-tuningu"""
    from openai import OpenAI
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    logger.info("ğŸš€ Rozpoczynanie fine-tuningu...")
    
    try:
        response = client.fine_tuning.jobs.create(
            training_file=training_file_id,
            model=BASE_MODEL_FOR_FINETUNING,
            suffix="lab-data-validator",
            seed=42  # Dodanie seed zgodnie z dokumentacjÄ…
        )
        
        job_id = response.id
        logger.info(f"âœ… Fine-tuning rozpoczÄ™ty. Job ID: {job_id}")
        return job_id
        
    except Exception as e:
        logger.error(f"âŒ BÅ‚Ä…d podczas rozpoczynania fine-tuningu: {e}")
        return None

def wait_for_fine_tuning(job_id: str) -> Optional[str]:
    """Czeka na zakoÅ„czenie fine-tuningu i zwraca ID modelu"""
    from openai import OpenAI
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    logger.info("â³ Czekam na zakoÅ„czenie fine-tuningu...")
    
    while True:
        try:
            job = client.fine_tuning.jobs.retrieve(job_id)
            status = job.status
            
            logger.info(f"   Status: {status}")
            
            if status == "succeeded":
                model_id = job.fine_tuned_model
                logger.info(f"âœ… Fine-tuning zakoÅ„czony! Model: {model_id}")
                return model_id
            elif status == "failed":
                logger.error(f"âŒ Fine-tuning zakoÅ„czony niepowodzeniem")
                logger.error(f"   SzczegÃ³Å‚y: {job}")
                return None
            elif status == "cancelled":
                logger.error(f"âŒ Fine-tuning zostaÅ‚ anulowany")
                return None
                
        except Exception as e:
            logger.error(f"âŒ BÅ‚Ä…d podczas sprawdzania statusu: {e}")
            return None
        
        # Czekaj 30 sekund przed kolejnym sprawdzeniem
        time.sleep(30)

def verify_sample(model_id: str, sample: str) -> bool:
    """Weryfikuje prÃ³bkÄ™ uÅ¼ywajÄ…c wytrenowanego modelu"""
    from openai import OpenAI
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    try:
        response = client.chat.completions.create(
            model=model_id,
            messages=[
                {"role": "system", "content": "validate data"},
                {"role": "user", "content": sample}
            ],
            temperature=0,
            max_tokens=1
        )
        
        result = response.choices[0].message.content.strip()
        return result == "1"
        
    except Exception as e:
        logger.error(f"âŒ BÅ‚Ä…d podczas weryfikacji prÃ³bki: {e}")
        return False

# 4. Nodes dla LangGraph
def download_data_node(state: PipelineState) -> PipelineState:
    """Pobiera i rozpakowuje dane laboratoryjne"""
    logger.info("ğŸ“ Przygotowywanie katalogu na dane...")
    
    data_dir = Path("lab_data")
    
    # JeÅ›li istniejÄ… pliki w dokumentach, uÅ¼yj ich
    if Path("correct.txt").exists() and Path("incorect.txt").exists() and Path("verify.txt").exists():
        logger.info("ğŸ“‚ Znaleziono pliki lokalne, kopiujÄ™ do katalogu roboczego...")
        data_dir.mkdir(parents=True, exist_ok=True)
        
        # Kopiuj pliki zachowujÄ…c oryginalne nazwy i poprawiajÄ…c bÅ‚Ä™dne
        Path("correct.txt").read_text(encoding="utf-8")
        (data_dir / "correct.txt").write_text(Path("correct.txt").read_text(encoding="utf-8"), encoding="utf-8")
        
        # Kopiuj incorect.txt jako incorrect.txt (poprawiona nazwa)
        (data_dir / "incorrect.txt").write_text(Path("incorect.txt").read_text(encoding="utf-8"), encoding="utf-8")
        (data_dir / "incorect.txt").write_text(Path("incorect.txt").read_text(encoding="utf-8"), encoding="utf-8")  # Zachowaj teÅ¼ oryginalnÄ… nazwÄ™
        
        (data_dir / "verify.txt").write_text(Path("verify.txt").read_text(encoding="utf-8"), encoding="utf-8")
        
        logger.info("âœ… Pliki skopiowane pomyÅ›lnie")
    else:
        # JeÅ›li nie ma lokalnych plikÃ³w, pobierz z URL
        download_and_extract_data(data_dir)
    
    state["lab_data_dir"] = data_dir
    return state

def prepare_training_node(state: PipelineState) -> PipelineState:
    """Przygotowuje dane treningowe"""
    data_dir = state.get("lab_data_dir")
    if not data_dir:
        logger.error("âŒ Brak katalogu z danymi")
        return state
    
    training_file = data_dir / "training_data.jsonl"
    sample_count = prepare_training_data(data_dir, training_file)
    
    if sample_count < 10:
        logger.error(f"âŒ Za maÅ‚o prÃ³bek treningowych: {sample_count} (minimum 10)")
        return state
    
    state["training_file_path"] = training_file
    return state

def upload_training_file_node(state: PipelineState) -> PipelineState:
    """WysyÅ‚a plik treningowy do OpenAI"""
    if args.skip_training:
        logger.info("â­ï¸  Pomijam wysyÅ‚anie pliku treningowego (--skip-training)")
        return state
    
    training_file = state.get("training_file_path")
    if not training_file:
        logger.error("âŒ Brak pliku treningowego")
        return state
    
    file_id = upload_training_file(training_file)
    state["training_file_id"] = file_id
    return state

def start_fine_tuning_node(state: PipelineState) -> PipelineState:
    """Rozpoczyna fine-tuning"""
    if args.skip_training:
        logger.info("â­ï¸  Pomijam fine-tuning (--skip-training)")
        if args.model_id:
            state["fine_tuned_model_id"] = args.model_id
            logger.info(f"ğŸ“Œ UÅ¼ywam modelu: {args.model_id}")
        else:
            logger.error("âŒ Brak --model-id przy --skip-training")
        return state
    
    file_id = state.get("training_file_id")
    if not file_id:
        logger.error("âŒ Brak ID pliku treningowego")
        return state
    
    job_id = start_fine_tuning(file_id)
    state["fine_tune_job_id"] = job_id
    return state

def wait_for_training_node(state: PipelineState) -> PipelineState:
    """Czeka na zakoÅ„czenie treningu"""
    if args.skip_training:
        logger.info("â­ï¸  Pomijam czekanie na trening (--skip-training)")
        return state
    
    job_id = state.get("fine_tune_job_id")
    if not job_id:
        logger.error("âŒ Brak ID zadania fine-tuningu")
        return state
    
    model_id = wait_for_fine_tuning(job_id)
    state["fine_tuned_model_id"] = model_id
    
    if model_id:
        logger.info(f"ğŸ’¡ Aby pominÄ…Ä‡ trening w przyszÅ‚oÅ›ci, uÅ¼yj:")
        logger.info(f"   python {sys.argv[0]} --skip-training --model-id {model_id}")
    
    return state

def verify_samples_node(state: PipelineState) -> PipelineState:
    """Weryfikuje prÃ³bki z pliku verify.txt"""
    model_id = state.get("fine_tuned_model_id")
    if not model_id:
        logger.error("âŒ Brak ID wytrenowanego modelu")
        return state
    
    data_dir = state.get("lab_data_dir")
    if not data_dir:
        logger.error("âŒ Brak katalogu z danymi")
        return state
    
    verify_file = data_dir / "verify.txt"
    if not verify_file.exists():
        logger.error(f"âŒ Nie znaleziono pliku: {verify_file}")
        return state
    
    logger.info("ğŸ” Weryfikacja prÃ³bek...")
    
    results = []
    correct_ids = []
    
    with open(verify_file, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            
            # Parsuj liniÄ™: ID=dane
            parts = line.split("=", 1)
            if len(parts) != 2:
                logger.warning(f"âš ï¸  NieprawidÅ‚owy format linii: {line}")
                continue
            
            sample_id = parts[0]
            sample_data = parts[1]
            
            # Weryfikuj prÃ³bkÄ™
            is_correct = verify_sample(model_id, sample_data)
            results.append((sample_id, is_correct))
            
            if is_correct:
                correct_ids.append(sample_id)
                logger.info(f"   âœ… {sample_id}: POPRAWNE")
            else:
                logger.info(f"   âŒ {sample_id}: SFAÅSZOWANE")
    
    state["verification_results"] = results
    state["correct_ids"] = correct_ids
    
    logger.info(f"ğŸ“Š Wyniki: {len(correct_ids)}/{len(results)} poprawnych")
    
    return state

def send_answer_node(state: PipelineState) -> PipelineState:
    """WysyÅ‚a wyniki do centrali"""
    correct_ids = state.get("correct_ids", [])
    
    if not correct_ids:
        logger.warning("âš ï¸  Brak poprawnych prÃ³bek do wysÅ‚ania")
    
    payload = {
        "task": "research",
        "apikey": CENTRALA_API_KEY,
        "answer": correct_ids
    }
    
    logger.info(f"ğŸ“¡ WysyÅ‚am {len(correct_ids)} poprawnych identyfikatorÃ³w...")
    logger.info(f"   IDs: {correct_ids}")
    
    try:
        response = requests.post(REPORT_URL, json=payload)
        response.raise_for_status()
        result = response.json()
        logger.info(f"âœ… OdpowiedÅº centrali: {result}")
        
        # SprawdÅ¼ czy jest flaga
        if "FLG" in str(result):
            print(f"ğŸ {result.get('message', result)}")
            state["result"] = result.get("message", str(result))
        
    except Exception as e:
        logger.error(f"âŒ BÅ‚Ä…d wysyÅ‚ania: {e}")
        if hasattr(e, 'response') and e.response:
            logger.error(f"   SzczegÃ³Å‚y: {e.response.text}")
    
    return state

def build_graph() -> Any:
    """Buduje graf LangGraph"""
    graph = StateGraph(state_schema=PipelineState)
    
    # Dodaj nodes
    graph.add_node("download_data", download_data_node)
    graph.add_node("prepare_training", prepare_training_node)
    graph.add_node("upload_training_file", upload_training_file_node)
    graph.add_node("start_fine_tuning", start_fine_tuning_node)
    graph.add_node("wait_for_training", wait_for_training_node)
    graph.add_node("verify_samples", verify_samples_node)
    graph.add_node("send_answer", send_answer_node)
    
    # Dodaj edges
    graph.add_edge(START, "download_data")
    graph.add_edge("download_data", "prepare_training")
    graph.add_edge("prepare_training", "upload_training_file")
    graph.add_edge("upload_training_file", "start_fine_tuning")
    graph.add_edge("start_fine_tuning", "wait_for_training")
    graph.add_edge("wait_for_training", "verify_samples")
    graph.add_edge("verify_samples", "send_answer")
    graph.add_edge("send_answer", END)
    
    return graph.compile()

def main() -> None:
    print("=== Zadanie 16: Wykrywanie sfaÅ‚szowanych danych ===")
    print(f"ğŸš€ UÅ¼ywam silnika: {ENGINE}")
    print(f"ğŸ”§ Model: {MODEL_NAME}")
    
    if args.skip_training:
        print(f"â­ï¸  Tryb: Pomijam trening")
        if args.model_id:
            print(f"ğŸ“Œ Model do uÅ¼ycia: {args.model_id}")
        else:
            print("âŒ Brak --model-id. Wymagany przy --skip-training")
            sys.exit(1)
    else:
        print(f"ğŸ¯ Model bazowy do fine-tuningu: {BASE_MODEL_FOR_FINETUNING}")
    
    # SprawdÅº dostÄ™pnoÅ›Ä‡ plikÃ³w
    local_files = Path("correct.txt").exists() and Path("incorect.txt").exists() and Path("verify.txt").exists()
    if local_files:
        print("ğŸ“‚ Znaleziono pliki lokalne - bÄ™dÄ… uÅ¼yte zamiast pobierania")
    else:
        print(f"ğŸŒ Pliki bÄ™dÄ… pobrane z: {LAB_DATA_URL}")
    
    print("Startuje pipeline...\n")
    
    try:
        graph = build_graph()
        result: PipelineState = graph.invoke({})
        
        if result.get("result"):
            print(f"\nğŸ‰ Zadanie zakoÅ„czone!")
        else:
            print("\nâœ… Proces zakoÅ„czony")
            
            # PokaÅ¼ podsumowanie
            if result.get("correct_ids"):
                print(f"\nğŸ“Š Znaleziono {len(result['correct_ids'])} poprawnych prÃ³bek:")
                print(f"   {result['correct_ids']}")
            
            if result.get("fine_tuned_model_id") and not args.skip_training:
                print(f"\nğŸ’¾ Wytrenowany model: {result['fine_tuned_model_id']}")
                print(f"   MoÅ¼esz go uÅ¼yÄ‡ pÃ³Åºniej z flagÄ…:")
                print(f"   --skip-training --model-id {result['fine_tuned_model_id']}")
            
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()