#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
S02E03 - Multi-engine obraz robota: OpenAI (DALL-E), LM Studio, Anything, Gemini (brak wsparcia), Claude (brak wsparcia), ComfyUI

- LM Studio i Anything uruchamiajƒÖ generowanie przez lokalny backend ComfyUI
- Dla ComfyUI wymagany workflow w formacie API (Save (API Format) w UI)
- Prompt pobierany dynamicznie z Centrali
- Claude NIE OBS≈ÅUGUJE generowania obraz√≥w - dodano komunikat informacyjny
- BEZPO≈öREDNIA INTEGRACJA Claude (jak zad1.py i zad2.py)
- POPRAWKA: Lepsze wykrywanie silnika z agent.py

Wymagane zmienne ≈õrodowiskowe (w .env):
- OPENAI_API_KEY, OPENAI_API_URL (opcjonalnie), MODEL_NAME_IMAGE
- REPORT_URL, CENTRALA_API_KEY, LOCAL_SD_API_URL
"""
import argparse
import glob
import json
import os
import platform
import re
import sys
import time
import uuid

import requests
from dotenv import load_dotenv

load_dotenv(override=True)

ANSI_GREEN = "\033[92m"
ANSI_RESET = "\033[0m"


def banner(title: str) -> str:
    if sys.stdout.isatty():
        return f"{ANSI_GREEN}=== {title} ==={ANSI_RESET}"
    return f"=== {title} ==="


def extract_flag(text: str) -> str:
    m = re.search(r"\{\{FLG:[^}]+\}\}|FLG\{[^}]+\}", text)
    return m.group(0) if m else ""


def convert_workflow_to_api(workflow_path):
    with open(workflow_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    if "nodes" in data:
        nodes_api = {str(node["id"]): node for node in data["nodes"]}
    else:
        nodes_api = {str(k): v for k, v in data.items()}
    return nodes_api


def generate_with_comfyui(prompt, workflow_path, local_sd_api_url, output_dir):
    workflow_api = convert_workflow_to_api(workflow_path)
    # Znajd≈∫ node CLIPTextEncode
    prompt_node_id = None
    for node_id, node in workflow_api.items():
        if node.get("class_type") == "CLIPTextEncode":
            prompt_node_id = node_id
            break
    if not prompt_node_id:
        prompt_node_id = [
            k
            for k, v in workflow_api.items()
            if v.get("class_type") == "CLIPTextEncode"
        ][0]
    workflow_api[prompt_node_id]["inputs"]["text"] = prompt
    # Ustaw filename_prefix dla SaveImage
    for node in workflow_api.values():
        if node.get("class_type") == "SaveImage":
            node["inputs"]["filename_prefix"] = "robot"

    client_id = str(uuid.uuid4())
    payload = {"prompt": workflow_api, "client_id": client_id}
    print(json.dumps(payload, indent=2, ensure_ascii=False))
    try:
        response = requests.post(f"{local_sd_api_url}/prompt", json=payload)
        response.raise_for_status()
        prompt_id = response.json().get("prompt_id")
        if not prompt_id:
            print("‚ùå Brak prompt_id w odpowiedzi ComfyUI.", file=sys.stderr)
            sys.exit(1)
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd wysy≈Çania ≈ºƒÖdania do ComfyUI: {e}", file=sys.stderr)
        sys.exit(1)

    # Poll na output_dir
    print("Czekam na wygenerowanie pliku w katalogu output...")
    last_time = time.time()
    timeout = 180
    found = None
    while time.time() - last_time < timeout:
        files = glob.glob(os.path.join(output_dir, "robot_*.png"))
        if files:
            latest_file = max(files, key=os.path.getctime)
            if os.path.getctime(latest_file) > last_time:
                found = latest_file
                break
        time.sleep(1.5)
    if found:
        print(f"Znaleziono plik: {found}")
        return found

    print(
        "‚ùå Nie uda≈Ço siƒô znale≈∫ƒá wygenerowanego obrazka po 3 minutach", file=sys.stderr
    )
    sys.exit(1)


def check_comfyui_api(url):
    try:
        requests.get(url, timeout=5)
    except Exception:
        print(
            "‚ùå Brak dzia≈ÇajƒÖcego backendu ComfyUI. Zainstaluj ComfyUI z https://www.comfy.org/download",
            file=sys.stderr,
        )
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(
        description="Generowanie obrazu robota (openai/lmstudio/anything/gemini/claude/comfyui)"
    )
    parser.add_argument(
        "--engine",
        choices=["openai", "lmstudio", "anything", "gemini", "claude", "comfyui"],
        help="Backend LLM do u≈ºycia",
    )
    parser.add_argument(
        "--workflow",
        default="robot.json",
        help="≈öcie≈ºka do pliku workflow ComfyUI (API format)",
    )
    parser.add_argument(
        "--output-dir",
        default=None,
        help="Katalog output ComfyUI (domy≈õlnie wykrywany)",
    )
    args = parser.parse_args()

    # POPRAWKA: Lepsze wykrywanie silnika (jak w poprawionych zad1.py-zad6.py)
    ENGINE = None
    if args.engine:
        ENGINE = args.engine.lower()
    elif os.getenv("LLM_ENGINE"):
        ENGINE = os.getenv("LLM_ENGINE").lower()
    else:
        # Pr√≥buj wykryƒá silnik na podstawie ustawionych zmiennych MODEL_NAME
        model_name = os.getenv("MODEL_NAME", "")
        if "claude" in model_name.lower():
            ENGINE = "claude"
        elif "gemini" in model_name.lower():
            ENGINE = "gemini"
        elif "gpt" in model_name.lower() or "openai" in model_name.lower():
            ENGINE = "openai"
        else:
            # Sprawd≈∫ kt√≥re API keys sƒÖ dostƒôpne
            if os.getenv("OPENAI_API_KEY"):
                ENGINE = "openai"  # DALL-E jest najlepszy do obraz√≥w
            elif os.getenv("LOCAL_SD_API_URL"):
                ENGINE = "comfyui"  # lokalna alternatywa
            else:
                ENGINE = "openai"  # domy≈õlnie (generowanie obraz√≥w wymaga chmury)

    if ENGINE not in {"openai", "lmstudio", "anything", "gemini", "claude", "comfyui"}:
        print(f"‚ùå Nieobs≈Çugiwany silnik: {ENGINE}", file=sys.stderr)
        sys.exit(1)

    print(f"üîÑ ENGINE wykryty: {ENGINE}")

    # Sprawdzenie czy wybrany silnik obs≈Çuguje generowanie obraz√≥w
    if ENGINE in {"claude", "gemini"}:
        print(f"‚ùå {ENGINE} nie obs≈Çuguje generowania obraz√≥w.", file=sys.stderr)
        print(
            "üí° U≈ºyj --engine openai (DALL-E) lub comfyui (lokalne) dla generowania obraz√≥w.",
            file=sys.stderr,
        )
        sys.exit(1)

    WORKFLOW = args.workflow

    # Ustal OUTPUT_DIR dynamicznie je≈õli nie podano
    if args.output_dir:
        OUTPUT_DIR = args.output_dir
    else:
        home = os.path.expanduser("~")
        if platform.system() == "Windows":
            OUTPUT_DIR = os.path.join(home, "ComfyUI", "output")
        else:
            OUTPUT_DIR = os.path.join(home, "ComfyUI", "output")

    # Zmienne ≈õrodowiskowe
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
    OPENAI_API_URL = os.getenv("OPENAI_API_URL", "https://api.openai.com/v1")
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
    REPORT_URL = os.getenv("REPORT_URL", "")
    CENTRALA_API_KEY = os.getenv("CENTRALA_API_KEY", "")
    LOCAL_SD_API_URL = os.getenv("LOCAL_SD_API_URL", "http://localhost:8074")
    MODEL_NAME_IMAGE = os.getenv(
        "MODEL_NAME_IMAGE", "dall-e-3"
    )  # U≈ºywaj dedykowanej zmiennej do obraz√≥w

    if not CENTRALA_API_KEY or not REPORT_URL:
        print(
            "‚ùå Brak ustawienia CENTRALA_API_KEY lub REPORT_URL w .env", file=sys.stderr
        )
        sys.exit(1)

    # Sprawdzenie wymaganych API keys/zasob√≥w
    if ENGINE == "openai" and not OPENAI_API_KEY:
        print("‚ùå Brak OPENAI_API_KEY dla DALL-E", file=sys.stderr)
        sys.exit(1)
    elif ENGINE in {"lmstudio", "anything", "comfyui"}:
        check_comfyui_api(LOCAL_SD_API_URL)

    print(f"‚úÖ Zainicjalizowano silnik: {ENGINE} z obs≈ÇugƒÖ generowania obraz√≥w")

    # 1. Pobranie opisu robota
    ROBOT_URL = os.getenv("ROBOT_URL")
    if ROBOT_URL is None:
        print("‚ùå Brak ROBOT_URL w .env", file=sys.stderr)
        sys.exit(1)

    print(banner("Opis robota (dynamiczny)"))
    try:
        resp = requests.get(ROBOT_URL, timeout=10)
        resp.raise_for_status()
        data = resp.json()
        description = data.get("description", "").strip()
    except Exception as e:
        print(
            f"‚ùå B≈ÇƒÖd pobierania lub parsowania JSON z {ROBOT_URL}: {e}",
            file=sys.stderr,
        )
        sys.exit(1)
    if not description:
        print("‚ùå Brak pola 'description' w odpowiedzi.", file=sys.stderr)
        sys.exit(1)
    print(description)
    prompt = description

    print(f"üöÄ U≈ºywam silnika: {ENGINE}")
    image_url = None

    if ENGINE == "openai":
        try:
            from openai import OpenAI
        except ImportError:
            print("‚ùå Zainstaluj openai (pip install openai)", file=sys.stderr)
            sys.exit(1)
        img_client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_API_URL)
        print(banner("Generowanie obrazu (OpenAI/DALL-E)"))
        print(f"[DEBUG] U≈ºywam modelu: {MODEL_NAME_IMAGE}")
        try:
            resp_img = img_client.images.generate(
                model=MODEL_NAME_IMAGE, prompt=prompt, n=1, size="1024x1024"
            )
            image_url = resp_img.data[0].url
            print(f"[üìä DALL-E - brak szczeg√≥≈Ç√≥w token√≥w]")
            print(f"[üí∞ DALL-E - sprawd≈∫ koszty w OpenAI Dashboard]")
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd generowania obrazu przez OpenAI: {e}", file=sys.stderr)
            sys.exit(1)
    elif ENGINE in {"lmstudio", "anything", "comfyui"}:
        print(banner("Generowanie obrazu (ComfyUI API)"))
        print(f"[DEBUG] Workflow: {WORKFLOW}")
        print(f"[DEBUG] Output dir: {OUTPUT_DIR}")
        image_url = generate_with_comfyui(
            prompt, WORKFLOW, LOCAL_SD_API_URL, OUTPUT_DIR
        )
        print(f"[üìä ComfyUI - model lokalny]")
        print(f"[üí∞ ComfyUI - brak koszt√≥w]")
    elif ENGINE == "claude":
        # Bezpo≈õrednia integracja Claude (jak w zad1.py i zad2.py)
        print(banner("‚ùå Claude (Anthropic) nie obs≈Çuguje generowania obraz√≥w!"))
        print("Claude jest modelem tekstowym i nie mo≈ºe generowaƒá obraz√≥w.")
        print("Dostƒôpne opcje:")
        print("1. U≈ºyj OpenAI (DALL-E): ustaw LLM_ENGINE=openai w .env")
        print("2. U≈ºyj ComfyUI (local): ustaw LLM_ENGINE=comfyui w .env")
        print("3. Uruchom ponownie agent.py i wybierz inny silnik")
        print(
            "\nClaude ≈õwietnie sprawdza siƒô w zadaniach tekstowych i analizy obraz√≥w (vision),"
        )
        print("ale nie mo≈ºe tworzyƒá nowych obraz√≥w.")
        sys.exit(2)
    elif ENGINE == "gemini":
        print(
            banner(
                "‚ùå Gemini (Google Generative AI) nie obs≈Çuguje generowania obraz√≥w!"
            )
        )
        print("Gemini w obecnej wersji nie obs≈Çuguje generowania obraz√≥w.")
        print("U≈ºyj OpenAI (DALL-E) lub ComfyUI (local)")
        sys.exit(2)
    else:
        print(f"‚ùå Nieobs≈Çugiwany silnik: {ENGINE}", file=sys.stderr)
        sys.exit(1)

    if not image_url:
        print("‚ùå Nie uzyskano URL/≈õcie≈ºki obrazu.", file=sys.stderr)
        sys.exit(1)
    print(banner("≈öcie≈ºka wygenerowanego obrazka"))
    print(image_url)

    # 4. Wys≈Çanie do Centrali
    print(banner("Wysy≈Çanie do Centrali"))
    payload = {"task": "robotid", "apikey": CENTRALA_API_KEY, "answer": image_url}
    try:
        r = requests.post(REPORT_URL, json=payload, timeout=10)
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd wysy≈Çania do Centrali: {e}", file=sys.stderr)
        sys.exit(1)
    if r.status_code == 403:
        print("‚ùå Centralna odrzuci≈Ça (HTTP 403).", file=sys.stderr)
        sys.exit(1)
    if not r.ok:
        print(f"‚ùå B≈ÇƒÖd HTTP {r.status_code}: {r.text}", file=sys.stderr)
        sys.exit(1)
    resp_text = r.text.strip()
    flag = extract_flag(resp_text)
    if flag:
        print(banner("Flaga"))
        print(flag)
    else:
        print("Brak flagi w odpowiedzi. Tekst serwera:", resp_text)


if __name__ == "__main__":
    main()
