#!/usr/bin/env python3
"""
S03E01 - przygotowanie metadanych do 10 raport√≥w dostarczonych w formacie TXT
Multi-engine: openai, lmstudio, anything, claude, gemini
Przygotowanie metadanych (s≈Ç√≥w kluczowych) dla raport√≥w fabryki - chunking, contextual retrieval, cache, analiza fakt√≥w.
"""
import argparse
import hashlib
import json
import os
import re
import sys
import zipfile
from pathlib import Path
from typing import Optional, Dict, Set, Tuple, List

import requests
from dotenv import load_dotenv

from zad9 import chunk_text

# POPRAWKA SONARA: Linia 242 - CRITICAL - sta≈Ça zamiast duplikacji litera≈Çu
BARBARA_ZAWADZKA = "barbara zawadzka"

# 1. Konfiguracja i wykrywanie silnika
load_dotenv(override=True)

parser = argparse.ArgumentParser(description="Metadane raport√≥w fabryki (multi-engine)")
parser.add_argument(
    "--engine",
    choices=["openai", "lmstudio", "anything", "gemini", "claude"],
    help="LLM backend do u≈ºycia",
)
args = parser.parse_args()

ENGINE = None
if args.engine:
    ENGINE = args.engine.lower()
elif os.getenv("LLM_ENGINE"):
    ENGINE = os.getenv("LLM_ENGINE").lower()
else:
    model_name = os.getenv("MODEL_NAME", "")
    if "claude" in model_name.lower():
        ENGINE = "claude"
    elif "gemini" in model_name.lower():
        ENGINE = "gemini"
    elif "gpt" in model_name.lower() or "openai" in model_name.lower():
        ENGINE = "openai"
    elif os.getenv("CLAUDE_API_KEY") or os.getenv("ANTHROPIC_API_KEY"):
        ENGINE = "claude"
    elif os.getenv("GEMINI_API_KEY"):
        ENGINE = "gemini"
    elif os.getenv("OPENAI_API_KEY"):
        ENGINE = "openai"
    else:
        ENGINE = "lmstudio"

if ENGINE not in {"openai", "lmstudio", "anything", "gemini", "claude"}:
    print(f"‚ùå Nieobs≈Çugiwany silnik: {ENGINE}", file=sys.stderr)
    sys.exit(1)
print(f"üîÑ ENGINE wykryty: {ENGINE}")

# 2. Inicjalizacja klienta/modelu
MODEL_NAME = None

if ENGINE == "openai":
    import openai

    openai.api_key = os.getenv("OPENAI_API_KEY")
    openai.api_base = os.getenv("OPENAI_API_URL", "https://api.openai.com/v1")
    MODEL_NAME = os.getenv("MODEL_NAME") or os.getenv("MODEL_NAME_OPENAI", "gpt-4o")
    if not openai.api_key:
        print("‚ùå Brak OPENAI_API_KEY", file=sys.stderr)
        sys.exit(1)

elif ENGINE == "claude":
    try:
        from anthropic import Anthropic
    except ImportError:
        print(
            "‚ùå Musisz zainstalowaƒá anthropic: pip install anthropic", file=sys.stderr
        )
        sys.exit(1)
    CLAUDE_API_KEY = os.getenv("CLAUDE_API_KEY") or os.getenv("ANTHROPIC_API_KEY")
    if not CLAUDE_API_KEY:
        print("‚ùå Brak CLAUDE_API_KEY lub ANTHROPIC_API_KEY", file=sys.stderr)
        sys.exit(1)
    MODEL_NAME = os.getenv("MODEL_NAME") or os.getenv(
        "MODEL_NAME_CLAUDE", "claude-sonnet-4-20250514"
    )
    claude_client = Anthropic(api_key=CLAUDE_API_KEY)

elif ENGINE == "gemini":
    import google.generativeai as genai

    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    if not GEMINI_API_KEY:
        print("‚ùå Brak GEMINI_API_KEY", file=sys.stderr)
        sys.exit(1)
    MODEL_NAME = os.getenv("MODEL_NAME") or os.getenv(
        "MODEL_NAME_GEMINI", "gemini-2.5-pro-latest"
    )
    genai.configure(api_key=GEMINI_API_KEY)
    model_gemini = genai.GenerativeModel(MODEL_NAME)

elif ENGINE == "lmstudio":
    MODEL_NAME = os.getenv("MODEL_NAME") or os.getenv("MODEL_NAME_LM", "qwen3-14b-128k")
    LMSTUDIO_API_URL = os.getenv("LMSTUDIO_API_URL", "http://localhost:1234/v1")

elif ENGINE == "anything":
    MODEL_NAME = os.getenv("MODEL_NAME") or os.getenv(
        "MODEL_NAME_ANY", "qwen3-14b-128k"
    )
    ANYTHING_API_URL = os.getenv("ANYTHING_API_URL", "http://localhost:1234/v1")

print(f"‚úÖ Zainicjalizowano silnik: {ENGINE} z modelem: {MODEL_NAME}")


# 3. Uniwersalna funkcja do LLM ‚Äì pewna obs≈Çuga operatora
def llm_request(prompt: str) -> str:
    if ENGINE == "openai":
        import openai

        resp = openai.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
        )
        return resp.choices[0].message.content.strip()
    elif ENGINE == "claude":
        resp = claude_client.messages.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            max_tokens=1000,
        )
        return resp.content[0].text.strip()
    elif ENGINE == "gemini":
        response = model_gemini.generate_content(
            [prompt], generation_config={"temperature": 0, "max_output_tokens": 1000}
        )
        return response.text.strip()
    elif ENGINE == "lmstudio":
        url = LMSTUDIO_API_URL.rstrip("/") + "/chat/completions"
        headers = {"Content-Type": "application/json"}
        payload = {
            "model": MODEL_NAME,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0,
        }
        resp = requests.post(url, json=payload, headers=headers)
        resp.raise_for_status()
        return resp.json()["choices"][0]["message"]["content"].strip()
    elif ENGINE == "anything":
        url = ANYTHING_API_URL.rstrip("/") + "/chat/completions"
        headers = {"Content-Type": "application/json"}
        payload = {
            "model": MODEL_NAME,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0,
        }
        resp = requests.post(url, json=payload, headers=headers)
        resp.raise_for_status()
        return resp.json()["choices"][0]["message"]["content"].strip()
    else:
        raise RuntimeError(f"Nieobs≈Çugiwany ENGINE: {ENGINE}")


# 4. Reszta logiki zadania ‚Äì jak wcze≈õniej
FABRYKA_URL = os.getenv("FABRYKA_URL")
REPORT_URL = os.getenv("REPORT_URL")
CENTRALA_API_KEY = os.getenv("CENTRALA_API_KEY")
if not REPORT_URL or not CENTRALA_API_KEY:
    raise RuntimeError("Brak REPORT_URL lub CENTRALA_API_KEY w .env")

CACHE_PATH = Path(".cache_context.json")
CACHE_PATH.parent.mkdir(exist_ok=True)


def load_cache():
    if CACHE_PATH.exists():
        return json.loads(CACHE_PATH.read_text(encoding="utf-8"))
    return {}


def save_cache(cache):
    CACHE_PATH.write_text(
        json.dumps(cache, ensure_ascii=False, indent=2), encoding="utf-8"
    )


EVENT_KEYWORDS = [
    "w≈Çamanie",
    "po≈ºar",
    "awaria",
    "wyciek",
    "kradzie≈º",
    "przerwa",
    "przest√≥j",
    "uszkodzenie",
    "zatrucie",
    "eksplozja",
]
# POPRAWKA SONARA: Linia 200 - MAJOR - usuniƒôcie duplikatu z character class
LOCATION_REGEX = re.compile(r"\b(?:sektor|hala)\s*[A-Za-z0-9]+\b", re.IGNORECASE)
TECH_KEYWORDS = [
    "czujnik",
    "robot",
    "system",
    "sterownik",
    "silnik",
    "panel",
    "sieƒá",
    "ultrad≈∫wiƒôki",
    "nadajnik",
    "skan",
    "detektor",
    "czujniki d≈∫wiƒôku",
]
PERSON_REGEX = re.compile(r"\b[A-Z≈Å≈ö≈ª≈π][a-zƒÖƒô√≥≈Ç≈õ≈º≈∫ƒá≈Ñ]+\s+[A-Z≈Å≈ö≈ª≈π][a-zƒÖƒô√≥≈Ç≈õ≈º≈∫ƒá≈Ñ]+\b")


# POPRAWKA SONARA: Linia 222 - MAJOR - poprawiona type hint
def extract_sector_from_filename(filename: str) -> Optional[str]:
    match = re.search(r"sektor[_\s]*([A-Z0-9]+)", filename, re.IGNORECASE)
    if match:
        return match.group(1).upper()
    return None


# POPRAWKA SONARA: Linia 225 - CRITICAL - podzielenie funkcji dla redukcji cognitive complexity
def _extract_people_from_report(report_text: str) -> Set[str]:
    """Helper function to extract people from report text"""
    people_in_report = set()
    for match in PERSON_REGEX.finditer(report_text):
        people_in_report.add(match.group(0).lower())
    return people_in_report


def _find_related_facts(people_in_report: Set[str], facts_map: Dict[str, str]) -> List[str]:
    """Helper function to find facts related to people in report"""
    related_facts = []
    for fact_key, fact_text in facts_map.items():
        for person in people_in_report:
            if person in fact_text.lower():
                related_facts.append(fact_text)
                break
    return related_facts


def _extract_person_professions(people_in_report: Set[str], facts_map: Dict[str, str]) -> Dict[str, str]:
    """Helper function to extract professions of people from facts"""
    person_professions = {}
    
    for fact_key, fact_text in facts_map.items():
        fact_lower = fact_text.lower()
        for person in people_in_report:
            if person not in fact_lower:
                continue
                
            if "nauczyciel" in fact_lower and person == "aleksander ragowski":
                person_professions[person] = "nauczyciel"
            elif "programista" in fact_lower:
                person_professions[person] = "programista"
            elif person == BARBARA_ZAWADZKA and "frontend" in fact_lower:
                person_professions[person] = "programista"
            break
    
    return person_professions


def contextualize_report_with_facts(report_text: str, facts_map: Dict[str, str]) -> Tuple[str, Dict[str, str]]:
    """POPRAWKA SONARA: Linia 225 - zredukowano cognitive complexity przez wydzielenie helper functions"""
    people_in_report = _extract_people_from_report(report_text)
    related_facts = _find_related_facts(people_in_report, facts_map)
    person_professions = _extract_person_professions(people_in_report, facts_map)
    
    context = f"RAPORT:\n{report_text}\n\n"
    if related_facts:
        context += "POWIƒÑZANE FAKTY:\n"
        for fact in related_facts:
            context += f"{fact}\n\n"
    
    return context, person_professions


def extract_keywords_with_context(full_context: str, filename: str, cache: dict) -> set:
    context_hash = hashlib.sha256((full_context + filename).encode("utf-8")).hexdigest()
    if context_hash in cache:
        return set(cache[context_hash])
    sector = extract_sector_from_filename(filename)
    prompt = f"""Przeanalizuj poni≈ºszy raport wraz z powiƒÖzanymi faktami.
Zwr√≥ƒá WSZYSTKIE istotne s≈Çowa kluczowe w jƒôzyku polskim, w mianowniku, oddzielone przecinkami.

WA≈ªNE ZASADY:
1. Je≈õli osoba jest wymieniona w raporcie, a w faktach jest informacja o jej zawodzie, KONIECZNIE uwzglƒôdnij ten zaw√≥d
2. Je≈õli raport opisuje schwytanie/aresztowanie/przekazanie do dzia≈Çu kontroli osoby, uwzglƒôdnij jej zaw√≥d
3. Uwzglƒôdnij imiona i nazwiska os√≥b
4. Uwzglƒôdnij lokalizacje (sektory, miejsca)
5. Uwzglƒôdnij technologie i urzƒÖdzenia
6. Uwzglƒôdnij wydarzenia i czynno≈õci
7. Je≈õli kto≈õ jest przekazany do "dzia≈Çu kontroli", dodaj: przechwycenie, aresztowanie
8. Je≈õli wspomniano odciski palc√≥w konkretnej osoby i raport jest z sektora {sector}, dodaj: "odciski palc√≥w w sektorze {sector}"
9. Je≈õli Barbara Zawadzka jest wymieniona w kontek≈õcie technologii, dodaj: JavaScript, frontend, programista
10. Je≈õli osoba nale≈ºy do ruchu oporu (wed≈Çug fakt√≥w), dodaj: ruch oporu

{full_context}

S≈Çowa kluczowe:"""
    keywords_text = llm_request(prompt)
    keywords = [w.strip().lower() for w in keywords_text.split(",") if w.strip()]
    cache[context_hash] = keywords
    save_cache(cache)
    return set(keywords)


# POPRAWKA SONARA: Linia 283 - CRITICAL - podzielenie funkcji dla redukcji cognitive complexity
def _add_filename_keywords(kws: Set[str], filename: str) -> None:
    """Helper function to add keywords from filename"""
    file_tokens = {
        tok.lower() for tok in re.split(r"[\W_]+", filename) if tok and len(tok) > 2
    }
    kws.update(file_tokens)


def _add_sector_keywords(kws: Set[str], filename: str) -> None:
    """Helper function to add sector keywords"""
    sector = extract_sector_from_filename(filename)
    if sector:
        kws.add(f"sektor {sector.lower()}")


def _add_people_keywords(kws: Set[str], report_text: str, person_professions: Dict[str, str]) -> List[str]:
    """Helper function to add people-related keywords"""
    people_found = []
    for match in PERSON_REGEX.finditer(report_text):
        name = match.group(0)
        kws.add(name.lower())
        people_found.append(name.lower())
        if name.lower() in person_professions:
            kws.add(person_professions[name.lower()])
    return people_found


def _add_event_keywords(kws: Set[str], report_text: str) -> None:
    """Helper function to add event keywords"""
    for evt in EVENT_KEYWORDS:
        if re.search(rf"\b{evt}\b", report_text, re.IGNORECASE):
            kws.add(evt)


def _add_location_keywords(kws: Set[str], report_text: str) -> None:
    """Helper function to add location keywords"""
    for loc in LOCATION_REGEX.findall(report_text):
        kws.add(loc.lower())


def _add_tech_keywords(kws: Set[str], report_text: str) -> None:
    """Helper function to add technology keywords"""
    for tech in TECH_KEYWORDS:
        if re.search(rf"\b{tech}\b", report_text, re.IGNORECASE):
            kws.add(tech)


def _add_special_keywords(kws: Set[str], report_text: str, filename: str) -> None:
    """Helper function to add special context keywords"""
    report_lower = report_text.lower()
    
    # Przechwycenie/aresztowanie
    if any(word in report_lower for word in ["przekazan", "kontroli", "schwyta", "aresztowa"]):
        kws.add("przechwycenie")
        kws.add("aresztowanie")
    
    # Zwierzƒôta
    if any(word in report_lower for word in ["zwierzyna", "fauna", "wildlife", "le≈õna"]):
        kws.add("zwierzƒôta")
    
    # Odciski palc√≥w
    if "odcisk" in report_lower:
        kws.add("odciski palc√≥w")
        kws.add("analiza odcisk√≥w palc√≥w")
        sector = extract_sector_from_filename(filename)
        if BARBARA_ZAWADZKA in report_lower and sector:
            kws.add(f"odciski palc√≥w w sektorze {sector.lower()}")
    
    # Las
    if any(word in report_lower for word in ["las", "krzak"]):
        kws.add("las")


def _add_person_specific_keywords(kws: Set[str], people_found: List[str]) -> None:
    """Helper function to add person-specific keywords"""
    for person in people_found:
        if person == BARBARA_ZAWADZKA:
            kws.update(["javascript", "frontend", "programista", "ruch oporu"])
        elif person == "aleksander ragowski":
            kws.update(["nauczyciel", "ruch oporu"])


def extract_keywords(report_text: str, filename: str, facts_map: Dict[str, str], cache: dict) -> Set[str]:
    """POPRAWKA SONARA: Linia 283 - zredukowano cognitive complexity przez wydzielenie helper functions"""
    kws = set()
    
    # Add filename-based keywords
    _add_filename_keywords(kws, filename)
    _add_sector_keywords(kws, filename)
    
    # Get context and professions
    full_context, person_professions = contextualize_report_with_facts(report_text, facts_map)
    context_keywords = extract_keywords_with_context(full_context, filename, cache)
    kws.update(context_keywords)
    
    # Add various keyword types
    people_found = _add_people_keywords(kws, report_text, person_professions)
    _add_event_keywords(kws, report_text)
    _add_location_keywords(kws, report_text)
    _add_tech_keywords(kws, report_text)
    _add_special_keywords(kws, report_text, filename)
    _add_person_specific_keywords(kws, people_found)
    
    return kws


def download_and_extract(dest: Path):
    dest.mkdir(parents=True, exist_ok=True)
    zip_path = dest / "fabryka.zip"
    print(f"üì• Pobieranie plik√≥w z {FABRYKA_URL}...")
    resp = requests.get(FABRYKA_URL, stream=True)
    resp.raise_for_status()
    with open(zip_path, "wb") as f:
        for chunk in resp.iter_content(8192):
            f.write(chunk)
    print("üì¶ Rozpakowywanie archiwum...")
    with zipfile.ZipFile(zip_path, "r") as zf:
        for member in zf.infolist():
            if member.filename.endswith("weapons_tests.zip"):
                continue
            zf.extract(member, dest)
    zip_path.unlink()
    print("‚úÖ Pliki rozpakowane")


def collect_files(dest: Path):
    reports, facts = [], []
    for p in dest.rglob("*.txt"):
        if "facts" in p.parts or "fakty" in p.parts:
            facts.append(p)
        else:
            reports.append(p)
    return reports, facts


def load_facts(facts_files):
    facts_map = {}
    for f in facts_files:
        facts_map[f.stem] = f.read_text(encoding="utf-8", errors="ignore")
    return facts_map


def main():
    print("üîÑ Rozpoczynam przetwarzanie raport√≥w...")
    base = Path("fabryka")
    download_and_extract(base)
    reports, facts = collect_files(base)
    print(f"üìÑ Znaleziono {len(reports)} raport√≥w i {len(facts)} plik√≥w z faktami")
    if len(reports) != 10:
        print(f"‚ö†Ô∏è  Oczekiwano 10 raport√≥w, znaleziono {len(reports)}")
    facts_map = load_facts(facts)
    cache = load_cache()
    answer = {}
    print("üîç Analizujƒô raporty...")
    for rpt in sorted(reports):
        print(f"  üìã Przetwarzam: {rpt.name}")
        text = rpt.read_text(encoding="utf-8", errors="ignore")
        kws = extract_keywords(text, rpt.name, facts_map, cache)
        answer[rpt.name] = ",".join(sorted(kws))
        print(f"     ‚úÖ Znaleziono {len(kws)} s≈Ç√≥w kluczowych")
    payload = {"task": "dokumenty", "apikey": CENTRALA_API_KEY, "answer": answer}
    print("\nüì§ Wysy≈Çam rozwiƒÖzanie...")
    resp = requests.post(REPORT_URL, json=payload)
    try:
        resp.raise_for_status()
        print("‚úÖ Sukces!", resp.json())
    except Exception as e:
        print("‚ùå B≈ÇƒÖd:", e)
        if resp.text:
            print("Odpowied≈∫ serwera:", resp.text)


if __name__ == "__main__":
    main()